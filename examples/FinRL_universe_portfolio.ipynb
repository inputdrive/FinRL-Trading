{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8cbede97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "import pandas as pd\n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "# 创建 NYSE 日历\n",
    "nyse = mcal.get_calendar(\"NYSE\")\n",
    "\n",
    "# 生成交易日（例如 1990 到 2030）\n",
    "schedule = nyse.schedule(start_date=\"1990-01-01\", end_date=\"2030-12-31\")\n",
    "\n",
    "# 得到实际交易日数组\n",
    "nyse_dates = mcal.date_range(schedule, frequency=\"1D\")\n",
    "nyse_dates = nyse_dates.tz_localize(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5fc707b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, logging\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from font\", category=UserWarning)\n",
    "def no_path_warning_format(message, category, filename, lineno, line=None):\n",
    "    return f\"{category.__name__}: {message}\\n\"\n",
    "\n",
    "warnings.formatwarning = no_path_warning_format\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  \n",
    "plt.rcParams['axes.unicode_minus'] = False     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557e076",
   "metadata": {},
   "source": [
    "### Strategy Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f1d3f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import queue\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  Async Writer Thread\n",
    "# ============================================================\n",
    "\n",
    "class AsyncWriterThread(threading.Thread):\n",
    "    \"\"\"\n",
    "    后台异步写日志线程：\n",
    "        - 主线程不断 push log 到队列\n",
    "        - 异步线程后台 flush 到文件\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_queue, flush_interval, base_dir):\n",
    "        super().__init__(daemon=True)\n",
    "        self.log_queue = log_queue\n",
    "        self.flush_interval = flush_interval\n",
    "        self.base_dir = base_dir\n",
    "        self.running = True\n",
    "\n",
    "        self.buffer = []         # 临时日志缓存\n",
    "        self.buffer_count = 0    # 累计条数，用来触发 flush\n",
    "\n",
    "    def write_to_disk(self, logs):\n",
    "        if not logs:\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(logs)\n",
    "\n",
    "        # 旋转文件夹\n",
    "        dstr = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "        day_dir = os.path.join(self.base_dir, dstr)\n",
    "        os.makedirs(day_dir, exist_ok=True)\n",
    "\n",
    "        fname = os.path.join(day_dir, \"async_logs.csv\")\n",
    "\n",
    "        # 写入模式：追加（append）\n",
    "        df.to_csv(fname, mode='a', header=not os.path.exists(fname), index=False)\n",
    "\n",
    "    def run(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                log = self.log_queue.get(timeout=1)\n",
    "\n",
    "                if log == \"__FLUSH__\":\n",
    "                    # 强制 flush\n",
    "                    self.write_to_disk(self.buffer)\n",
    "                    self.buffer = []\n",
    "                    self.buffer_count = 0\n",
    "                    continue\n",
    "\n",
    "                # 写入缓存\n",
    "                self.buffer.append(log)\n",
    "                self.buffer_count += 1\n",
    "\n",
    "                # 超过 interval → flush\n",
    "                if self.buffer_count >= self.flush_interval:\n",
    "                    self.write_to_disk(self.buffer)\n",
    "                    self.buffer = []\n",
    "                    self.buffer_count = 0\n",
    "\n",
    "            except queue.Empty:\n",
    "                # 没有新任务，检查是否需要 flush\n",
    "                if self.buffer_count > 0:\n",
    "                    self.write_to_disk(self.buffer)\n",
    "                    self.buffer = []\n",
    "                    self.buffer_count = 0\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        # Flush before exit\n",
    "        self.write_to_disk(self.buffer)\n",
    "        self.buffer = []\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  StrategyLogger Advanced\n",
    "# ============================================================\n",
    "\n",
    "class StrategyLogger:\n",
    "    \"\"\"\n",
    "    StrategyLogger (Advanced Version)\n",
    "    ---------------------------------\n",
    "    扩展功能:\n",
    "        ✔ flush_interval (避免内存暴涨)\n",
    "        ✔ log rotation (按日生成文件夹)\n",
    "        ✔ async 异步写入 (不阻塞主策略)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        strategy_name=\"strategy\",\n",
    "        log_dir=\"./log\",\n",
    "        async_mode=True,\n",
    "        flush_interval=5000\n",
    "    ):\n",
    "        self.strategy_name = strategy_name\n",
    "        self.log_dir = os.path.join(log_dir, f\"strategy_{strategy_name}\")\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "\n",
    "        # Async 模式\n",
    "        self.async_mode = async_mode\n",
    "        self.flush_interval = flush_interval\n",
    "\n",
    "        # 队列: 主线程 push, 异步线程 pull\n",
    "        self.log_queue = queue.Queue()\n",
    "\n",
    "        # 启动异步线程\n",
    "        if self.async_mode:\n",
    "            self.writer_thread = AsyncWriterThread(\n",
    "                log_queue=self.log_queue,\n",
    "                flush_interval=self.flush_interval,\n",
    "                base_dir=self.log_dir\n",
    "            )\n",
    "            self.writer_thread.start()\n",
    "\n",
    "        # Memory logs（不用于写文件，仅用于快速调试）\n",
    "        self.signal_logs = []\n",
    "        self.universe_logs = []\n",
    "        self.portfolio_logs = []\n",
    "        self.error_logs = []\n",
    "        self.feature_logs = {}\n",
    "        self.raw_signal_logs = {}\n",
    "        self.filtered_signal_logs = {}\n",
    "\n",
    "    # ============================================================\n",
    "    # Unified Log Method → push to queue\n",
    "    # ============================================================\n",
    "\n",
    "    def _push_log(self, log_dict, category=\"generic\"):\n",
    "        \"\"\"\n",
    "        push log to async queue\n",
    "        \"\"\"\n",
    "        if self.async_mode:\n",
    "            log_dict[\"category\"] = category\n",
    "            self.log_queue.put(log_dict)\n",
    "        else:\n",
    "            # fallback to memory logs only\n",
    "            if category == \"signal\":\n",
    "                self.signal_logs.append(log_dict)\n",
    "            elif category == \"portfolio\":\n",
    "                self.portfolio_logs.append(log_dict)\n",
    "            elif category == \"universe\":\n",
    "                self.universe_logs.append(log_dict)\n",
    "            elif category == \"error\":\n",
    "                self.error_logs.append(log_dict)\n",
    "\n",
    "    # ============================================================\n",
    "    # Logging Methods\n",
    "    # ============================================================\n",
    "    def log_signal(self, date, symbol, signal, action, old_weight, new_weight, close_only=False, cooldown_left=0):\n",
    "        self._push_log({\n",
    "            \"date\": pd.Timestamp(date),\n",
    "            \"symbol\": symbol,\n",
    "            \"signal\": signal,\n",
    "            \"action\": action,\n",
    "            \"old_weight\": old_weight,\n",
    "            \"new_weight\": new_weight,\n",
    "            \"close_only\": close_only,\n",
    "            \"cooldown_left\": cooldown_left\n",
    "        }, category=\"signal\")\n",
    "\n",
    "    def log_portfolio(self, date, portfolio_dict):\n",
    "        self._push_log({\n",
    "            \"date\": pd.Timestamp(date),\n",
    "            **portfolio_dict\n",
    "        }, category=\"portfolio\")\n",
    "\n",
    "    def log_universe(self, date, symbol, in_universe, close_only=False, has_position=False):\n",
    "        self._push_log({\n",
    "            \"date\": pd.Timestamp(date),\n",
    "            \"symbol\": symbol,\n",
    "            \"in_universe\": int(in_universe),\n",
    "            \"close_only\": int(close_only),\n",
    "            \"has_position\": int(has_position)\n",
    "        }, category=\"universe\")\n",
    "\n",
    "    def log_error(self, msg):\n",
    "        self._push_log({\"error\": msg}, category=\"error\")\n",
    "\n",
    "    # Feature logs are stored in-memory only (not frequent)\n",
    "    def log_feature(self, tic, df):\n",
    "        self.feature_logs[tic] = df.copy()\n",
    "\n",
    "    def log_raw_signal(self, tic, sig):\n",
    "        self.raw_signal_logs[tic] = sig.copy()\n",
    "\n",
    "    def log_filtered_signal(self, df):\n",
    "        self.filtered_signal_logs[\"signal_df\"] = df.copy()\n",
    "\n",
    "    # ============================================================\n",
    "    # Force flush\n",
    "    # ============================================================\n",
    "    def flush(self):\n",
    "        \"\"\"\n",
    "        强制刷写日志到文件\n",
    "        \"\"\"\n",
    "        if self.async_mode:\n",
    "            self.log_queue.put(\"__FLUSH__\")\n",
    "\n",
    "    # ============================================================\n",
    "    # Terminate writer thread\n",
    "    # ============================================================\n",
    "    def close(self):\n",
    "        if self.async_mode:\n",
    "            self.writer_thread.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea7e89",
   "metadata": {},
   "source": [
    "###  UniverseManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5e8b1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class UniverseManager:\n",
    "    \"\"\"\n",
    "    UniverseManager (Final Version, Logger-compatible)\n",
    "    --------------------------------------------------\n",
    "    * 自动从季度选股生成日度股票池\n",
    "    * 不关心持仓\n",
    "    * 只负责 in_universe 的判断\n",
    "    * 事件日志兼容增强版 StrategyLogger\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        stock_selection_df,\n",
    "        col_map,\n",
    "        trading_calendar,\n",
    "        logger=None,\n",
    "        backtest_start=None,\n",
    "        backtest_end=None,\n",
    "    ):\n",
    "        self.logger = logger\n",
    "        self.trading_calendar = pd.DatetimeIndex(sorted(trading_calendar))\n",
    "\n",
    "        # === save backtest start and end ===\n",
    "        self.backtest_start = pd.to_datetime(backtest_start) if backtest_start else None\n",
    "        self.backtest_end   = pd.to_datetime(backtest_end) if backtest_end else None\n",
    "\n",
    "        # -----------------------------\n",
    "        # map column names\n",
    "        # -----------------------------\n",
    "        df = stock_selection_df.copy()\n",
    "        df = df.rename(columns={\n",
    "            col_map[\"tic_name\"]: \"tic_name\",\n",
    "            col_map[\"trade_date\"]: \"trade_date\"\n",
    "        })\n",
    "        df[\"trade_date\"] = pd.to_datetime(df[\"trade_date\"])\n",
    "\n",
    "        # === select backtest period ===\n",
    "        if self.backtest_start is not None:\n",
    "            df = df[df[\"trade_date\"] >= self.backtest_start]\n",
    "\n",
    "        if self.backtest_end is not None:\n",
    "            df = df[df[\"trade_date\"] <= self.backtest_end]\n",
    "\n",
    "\n",
    "        # -----------------------------\n",
    "        # build daily universe_df\n",
    "        # -----------------------------\n",
    "        self.universe_df = self._build_universe(df)\n",
    "\n",
    "        # -----------------------------\n",
    "        # build fast index\n",
    "        # -----------------------------\n",
    "        self.universe_map = self._build_fast_index(self.universe_df)\n",
    "\n",
    "        # save yesterday's universe, for IN / OUT judgment\n",
    "        self.prev_universe = set()\n",
    "        \n",
    "        # === log feedback ===\n",
    "        if self.logger:\n",
    "            self.logger.log_error(\n",
    "                f\"[UniverseManager] Loaded {len(self.universe_df)} daily rows, \"\n",
    "                f\"backtest=[{self.backtest_start} ~ {self.backtest_end}]\"\n",
    "            )\n",
    "\n",
    "    # ============================================================\n",
    "    # Internal Helpers\n",
    "    # ============================================================\n",
    "\n",
    "    def _next_trade_date(self, date):\n",
    "        date = pd.Timestamp(date)\n",
    "        pos = self.trading_calendar.searchsorted(date, side=\"right\")\n",
    "        if pos >= len(self.trading_calendar):\n",
    "            return None\n",
    "        return self.trading_calendar[pos]\n",
    "\n",
    "    def _build_universe(self, df):\n",
    "        df = df.copy()\n",
    "        df[\"activate_date\"] = df[\"trade_date\"].apply(self._next_trade_date)\n",
    "        df = df.dropna(subset=[\"activate_date\"])\n",
    "\n",
    "        df = df.sort_values([\"trade_date\", \"tic_name\"])\n",
    "        quarters = df.groupby(\"trade_date\")\n",
    "\n",
    "        trade_dates = sorted(df[\"trade_date\"].unique())\n",
    "        activate_dates = [self._next_trade_date(d) for d in trade_dates]\n",
    "\n",
    "        deactivate_map = {}\n",
    "        for i in range(len(activate_dates)-1):\n",
    "            deactivate_map[activate_dates[i]] = activate_dates[i+1]\n",
    "\n",
    "        max_date = self.trading_calendar.max() + pd.Timedelta(days=1)\n",
    "        deactivate_map[activate_dates[-1]] = max_date\n",
    "\n",
    "        # ⬇ build daily universe\n",
    "        records = []\n",
    "\n",
    "        for trade_date, group in quarters:\n",
    "            act_date = self._next_trade_date(trade_date)\n",
    "            deact_date = deactivate_map[act_date]\n",
    "\n",
    "            tics = group[\"tic_name\"].tolist()\n",
    "            mask = (self.trading_calendar >= act_date) & (self.trading_calendar < deact_date)\n",
    "            active_days = self.trading_calendar[mask]\n",
    "\n",
    "            for d in active_days:\n",
    "                for tic in tics:\n",
    "                    records.append({\n",
    "                        \"date\": d,\n",
    "                        \"tic_name\": tic,\n",
    "                        \"in_universe\": 1\n",
    "                    })\n",
    "\n",
    "        universe_df = (\n",
    "            pd.DataFrame(records)\n",
    "              .drop_duplicates([\"date\", \"tic_name\"])\n",
    "              .sort_values([\"date\", \"tic_name\"])\n",
    "        )\n",
    "        return universe_df\n",
    "\n",
    "    def _build_fast_index(self, universe_df):\n",
    "        fast = {}\n",
    "        for date, grp in universe_df.groupby(\"date\"):\n",
    "            fast[pd.Timestamp(date)] = set(grp[\"tic_name\"].tolist())\n",
    "        return fast\n",
    "\n",
    "    # ============================================================\n",
    "    # Public API\n",
    "    # ============================================================\n",
    "\n",
    "    def is_in_universe(self, tic_name, date):\n",
    "        date = pd.Timestamp(date)\n",
    "        tics = self.universe_map.get(date)\n",
    "        if tics is None:\n",
    "            return False\n",
    "        return tic_name in tics\n",
    "\n",
    "    def get_universe(self, date):\n",
    "        date = pd.Timestamp(date)\n",
    "        return self.universe_map.get(date, set())\n",
    "\n",
    "    # ============================================================\n",
    "    # Universe Logging (IN / OUT)\n",
    "    # ============================================================\n",
    "\n",
    "    def log_universe_events_for_date(self, date):\n",
    "        \"\"\"\n",
    "        仅记录股票池的 IN / OUT（Execution 决定 close-only）\n",
    "        \"\"\"\n",
    "        if self.logger is None:\n",
    "            return\n",
    "\n",
    "        date = pd.Timestamp(date)\n",
    "        today_u = self.get_universe(date)\n",
    "\n",
    "        added = today_u - self.prev_universe\n",
    "        removed = self.prev_universe - today_u\n",
    "\n",
    "        # --- modified: use logger's compatible signature ---\n",
    "        for tic in sorted(added):\n",
    "            self.logger.log_universe(\n",
    "                date=date,\n",
    "                symbol=tic,\n",
    "                in_universe=1,\n",
    "                close_only=False,\n",
    "                has_position=False\n",
    "            )\n",
    "\n",
    "        for tic in sorted(removed):\n",
    "            self.logger.log_universe(\n",
    "                date=date,\n",
    "                symbol=tic,\n",
    "                in_universe=0,\n",
    "                close_only=False,\n",
    "                has_position=False\n",
    "            )\n",
    "        # --- end of modification ---\n",
    "\n",
    "        self.prev_universe = today_u.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4ee95",
   "metadata": {},
   "source": [
    "### ExecutionManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "aa0781f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, Optional\n",
    "\n",
    "\n",
    "class ExecutionManager:\n",
    "    \"\"\"\n",
    "    ExecutionManager (Final Version)\n",
    "    --------------------------------\n",
    "    职责：\n",
    "      - 根据 Universe + 日度信号（-1/0/1）生成每日目标权重矩阵\n",
    "      - 支持：\n",
    "          * 冷静期（卖出后 X 天不能再开仓）\n",
    "          * 调仓频率（日频 / 月频，可扩展）\n",
    "          * 组合层面约束：max_positions / max_weight / min_weight / gross_leverage\n",
    "          * close-only（退出股票池后只允许减仓/平仓，不再加仓）\n",
    "      - 可选接入 logger 记录信号与权重变化\n",
    "\n",
    "    不负责：\n",
    "      - PnL 计算\n",
    "      - 手数 / 资金换算\n",
    "      - 回测窗口裁剪（由外部控制）\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        universe_mgr,\n",
    "        max_positions: int = 20,\n",
    "        max_weight: float = 0.20,\n",
    "        min_weight: float = 0.05,\n",
    "        weight_step: float = 0.05,\n",
    "        allow_short: bool = True,\n",
    "        gross_leverage: float = 1.0,\n",
    "        cooling_days: int = 0,\n",
    "        rebalance_freq: str = \"D\",  # \"D\"（日频）或者 \"M\"（月频）,\"W\"（周频），未来可扩展\n",
    "        logger: Optional[object] = None,\n",
    "        ratio: float = 1.0,           # 最大可用资金比例\n",
    "        seed: int = 42                # 固定随机性\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        universe_mgr : UniverseManager\n",
    "            已初始化好的 UniverseManager，用于判断股票是否在池子\n",
    "        max_positions : int\n",
    "            最大持仓股票数（按 |weight| > 0 计）\n",
    "        max_weight : float\n",
    "            单个股票最大绝对权重（如 0.2 = 20%）\n",
    "        min_weight : float\n",
    "            单个股票最小非零绝对权重（如 0.05 = 5%），低于此绝对值直接视为 0\n",
    "        weight_step : float\n",
    "            每次调整权重的步长（如 0.05）\n",
    "        allow_short : bool\n",
    "            是否允许做空（weight < 0）\n",
    "        gross_leverage : float\n",
    "            组合总 |weight| 之和上限（如 1.0 = 100%）\n",
    "        cooling_days : int\n",
    "            冷静期天数：卖出 / 平仓后需要等待的交易日数，期间禁止重新开仓\n",
    "        rebalance_freq : str\n",
    "            调仓频率：\n",
    "              - \"D\"：每日调仓\n",
    "              - \"M\"：每月调仓（默认用月内第二个交易日）\n",
    "              - \"W\"：每周调仓（默认用周内第一个交易日）\n",
    "              - 可预留扩展 \"W\"、\"intraday\" 等\n",
    "        logger : object or None\n",
    "            可选日志对象，需实现 log_signal(...)\n",
    "        \"\"\"\n",
    "        self.universe_mgr = universe_mgr\n",
    "        self.max_positions = int(max_positions)\n",
    "        self.max_weight = float(max_weight)\n",
    "        self.min_weight = float(min_weight)\n",
    "        self.weight_step = float(weight_step)\n",
    "        self.allow_short = allow_short\n",
    "        self.gross_leverage = float(gross_leverage)\n",
    "        self.cooling_days = int(cooling_days)\n",
    "        self.rebalance_freq = rebalance_freq.upper()\n",
    "        self.logger = logger\n",
    "        self.ratio = ratio\n",
    "        random.seed(seed)\n",
    "\n",
    "        # 当前目标权重：tic_name -> weight (可为负，表示空头)\n",
    "        self.current_weights: Dict[str, float] = {}\n",
    "\n",
    "        # 冷静期计数器：tic_name -> 剩余冷静天数\n",
    "        self.cooldown: Dict[str, int] = {}\n",
    "\n",
    "        # 上一日日期，用于 close-only 判断\n",
    "        self.prev_date: Optional[pd.Timestamp] = None\n",
    "\n",
    "    def set_rebalance_frequency(self, freq: str):\n",
    "        \"\"\"\n",
    "        freq: 'D' / 'W' / 'M'\n",
    "        \"\"\"\n",
    "        self.rebalance_freq = freq.upper()\n",
    "    # =========================================================\n",
    "    # 公共主入口：根据 signal_df 生成全历史权重矩阵\n",
    "    # =========================================================\n",
    "    def generate_weight_matrix(self, signal_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        generate a weight matrix (index=date, columns=tic_name, value=weight)\n",
    "        based on the daily signal_df (index=date, columns=tic_name, value=-1/0/1)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        signal_df : pd.DataFrame\n",
    "            index：日期（DatetimeIndex 或可转为 Timestamp）\n",
    "            columns：tic_name\n",
    "            values：-1 / 0 / 1\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        weights_df : pd.DataFrame\n",
    "            index：日期\n",
    "            columns：tic_name\n",
    "            values：权重（float）\n",
    "        \"\"\"\n",
    "        dates = sorted(pd.to_datetime(signal_df.index.unique()))\n",
    "        all_tics = sorted(signal_df.columns.unique())\n",
    "\n",
    "        records = []\n",
    "\n",
    "\n",
    "        for dt in dates:\n",
    "            # get the signal of the day\n",
    "            row = signal_df.loc[dt]\n",
    "            if isinstance(row, pd.DataFrame):\n",
    "                # if there are multiple rows (uncommon), take the first row\n",
    "                signal_series = row.iloc[0]\n",
    "            else:\n",
    "                signal_series = row\n",
    "\n",
    "            self.step(dt, signal_series)\n",
    "\n",
    "            # record the weights of the day\n",
    "            row_weights = {tic: self.current_weights.get(tic, 0.0) for tic in all_tics}\n",
    "            row_weights[\"date\"] = pd.Timestamp(dt)\n",
    "            records.append(row_weights)\n",
    "        #  calculate the target weight matrix\n",
    "\n",
    "        weights_df = pd.DataFrame(records).set_index(\"date\").sort_index()\n",
    "\n",
    "        if hasattr(self, \"_compute_target_weights\"):\n",
    "            try:\n",
    "                target_df = self._compute_target_weights(signal_df)\n",
    "                # align the index and columns (take the intersection to avoid column inconsistency)\n",
    "                target_df = target_df.reindex_like(weights_df).fillna(0.0)\n",
    "                # use the target weights to cover the current weights matrix\n",
    "                weights_df.update(target_df)\n",
    "                if self.logger:\n",
    "                    self.logger.log_info(\"[ExecutionManager] Applied _compute_target_weights successfully.\")\n",
    "            except Exception as e:\n",
    "                if self.logger:\n",
    "                    self.logger.log_error(f\"[ExecutionManager] _compute_target_weights failed: {e}\")\n",
    "                else:\n",
    "                    print(f\"[WARN] _compute_target_weights failed: {e}\")\n",
    "\n",
    "        return weights_df\n",
    "\n",
    "    # frequency control of rebalance\n",
    "    def _should_rebalance(self, date: pd.Timestamp) -> bool:\n",
    "        \"\"\"\n",
    "        based on the rebalance_freq, determine if the current date needs to rebalance.\n",
    "        currently supported:\n",
    "          - \"D\"：Day \n",
    "          - \"M\"：Month \n",
    "        \"\"\"\n",
    "        date = pd.Timestamp(date)\n",
    "\n",
    "        if self.rebalance_freq == \"D\":\n",
    "            return True\n",
    "\n",
    "        if self.rebalance_freq == \"W\":\n",
    "            cal = self.universe_mgr.trading_calendar\n",
    "            # find the trading days of the week\n",
    "            week_dates = [d for d in cal\n",
    "                          if d.isocalendar()[1] == date.isocalendar()[1]\n",
    "                          and d.year == date.year]\n",
    "            if not week_dates:\n",
    "                return False\n",
    "            week_dates = sorted(week_dates)\n",
    "            return date.normalize() == week_dates[0].normalize()\n",
    "\n",
    "        if self.rebalance_freq == \"M\":\n",
    "            cal = self.universe_mgr.trading_calendar\n",
    "            month_dates = [d for d in cal if d.year == date.year and d.month == date.month]\n",
    "            if not month_dates:\n",
    "                return False\n",
    "            month_dates = sorted(month_dates)\n",
    "            # 第二个交易日 & 月末最后一个交易日\n",
    "            second_day = month_dates[1] if len(month_dates) >= 2 else month_dates[0]\n",
    "            last_day = month_dates[-1]\n",
    "            return date.normalize() in [\n",
    "                pd.Timestamp(second_day).normalize(),\n",
    "                pd.Timestamp(last_day).normalize()\n",
    "            ]\n",
    "\n",
    "    # daily execution logic: update self.current_weights\n",
    "    def step(self, date, signal_series: pd.Series):\n",
    "        \"\"\"\n",
    "        single day execution logic:\n",
    "          1. Decrement cooldown period for each stock.\n",
    "          2. Check if today is a rebalance day based on the strategy's settings.\n",
    "          3. If today is a rebalance day:\n",
    "             - Adjust weights according to Universe membership, signals, close-only rule, and cooldown status\n",
    "             - Apply portfolio constraints such as max_positions and gross_leverage\n",
    "        \"\"\"\n",
    "        date = pd.Timestamp(date)\n",
    "        signals = signal_series.to_dict()  # tic -> -1/0/1\n",
    "\n",
    "        #  decrement the cooldown period for each stock\n",
    "        for tic in list(self.cooldown.keys()):\n",
    "            if self.cooldown[tic] > 0:\n",
    "                self.cooldown[tic] -= 1\n",
    "\n",
    "        #  update prev_date (for close-only judgment)\n",
    "        prev_date = self.prev_date\n",
    "        self.prev_date = date\n",
    "\n",
    "        # if not a rebalance day, do not change the weights (cooldown period still decrements)\n",
    "        if not self._should_rebalance(date):\n",
    "            return\n",
    "\n",
    "        # the universe of stocks that are allowed to open new positions today\n",
    "        today_universe = self.universe_mgr.get_universe(date)\n",
    "\n",
    "        current_positions = {tic for tic, w in self.current_weights.items() if abs(w) > 0}\n",
    "\n",
    "        # all the stocks that need to be considered: have signal or have positions\n",
    "        all_tics = sorted(set(signals.keys()) | current_positions)\n",
    "\n",
    "        new_weights = self.current_weights.copy()\n",
    "\n",
    "        for tic in all_tics:\n",
    "            old_w = float(self.current_weights.get(tic, 0.0))\n",
    "            sig = int(signals.get(tic, 0))\n",
    "\n",
    "            # cooldown status\n",
    "            cd = int(self.cooldown.get(tic, 0))\n",
    "            has_pos = abs(old_w) > 0\n",
    "\n",
    "            in_uni_today = tic in today_universe\n",
    "            in_uni_yday = False\n",
    "            if prev_date is not None:\n",
    "                in_uni_yday = self.universe_mgr.is_in_universe(tic, prev_date)\n",
    "\n",
    "            # close-only: yesterday in the pool & today not in the pool & still have positions\n",
    "            close_only = in_uni_yday and (not in_uni_today) and has_pos\n",
    "\n",
    "            # if no positions and in cooldown period, do not open new positions (regardless of the signal)\n",
    "            if (not has_pos) and cd > 0:\n",
    "                effective_sig = 0\n",
    "            else:\n",
    "                effective_sig = sig\n",
    "\n",
    "            # decide the target direction today (0/+1/-1)\n",
    "            if effective_sig == 0:\n",
    "                # signal is 0: immediately close\n",
    "                new_w = 0.0\n",
    "\n",
    "            elif close_only:\n",
    "                # close-only: do not open new positions; only keep the original position\n",
    "                # if the signal turns to 0, close (already covered above)\n",
    "                new_w = old_w\n",
    "                print(f\"[CLOSE-ONLY] {tic} keep position {old_w:.2f} (still have positions in the pool)\")\n",
    "\n",
    "            elif effective_sig > 0 and in_uni_today:\n",
    "                target_sign = 1\n",
    "                new_w = self._update_weight_one_name(\n",
    "                    old_weight=old_w, target_sign=target_sign, close_only=False, target_weight=self.max_weight, \n",
    "                )\n",
    "\n",
    "            elif effective_sig < 0 and in_uni_today and self.allow_short:\n",
    "                target_sign = -1\n",
    "                new_w = self._update_weight_one_name(\n",
    "                    old_weight=old_w, target_sign=target_sign, close_only=False,target_weight=self.max_weight, \n",
    "                )\n",
    "\n",
    "            else:\n",
    "                # not in the universe today & no positions → force 0\n",
    "                new_w = 0.0\n",
    "\n",
    "            # update the weight of the day\n",
    "            new_weights[tic] = new_w\n",
    "\n",
    "            # if the position changes from non-zero to 0 → start the cooldown period\n",
    "            if (abs(old_w) > 0) and (abs(new_w) == 0) and (self.cooling_days > 0):\n",
    "                self.cooldown[tic] = self.cooling_days\n",
    "\n",
    "            # log\n",
    "            if self.logger is not None:\n",
    "                if abs(old_w - new_w) > 1e-8:\n",
    "                    action = \"HOLD\"\n",
    "                    if old_w == 0 and new_w != 0:\n",
    "                        action = \"OPEN_LONG\" if new_w > 0 else \"OPEN_SHORT\"\n",
    "                    elif old_w != 0 and new_w == 0:\n",
    "                        action = \"CLOSE\"\n",
    "                    elif old_w * new_w < 0:\n",
    "                        action = \"FLIP\"\n",
    "                    else:\n",
    "                        action = \"ADJUST\"\n",
    "\n",
    "                    self.logger.log_signal(\n",
    "                        date=date,\n",
    "                        symbol=tic,\n",
    "                        signal=effective_sig,\n",
    "                        action=action,\n",
    "                        old_weight=old_w,\n",
    "                        new_weight=new_w,\n",
    "                        close_only=close_only,\n",
    "                        cooldown_left=self.cooldown.get(tic, 0),\n",
    "                    )\n",
    "\n",
    "        # ========= portfolio level constraints =========\n",
    "\n",
    "        # 1) limit the number of positions\n",
    "        nz = [(tic, w) for tic, w in new_weights.items() if abs(w) > 0]\n",
    "        if len(nz) > self.max_positions:\n",
    "            # sort by |weight| in descending order, keep the top max_positions\n",
    "            nz_sorted = sorted(nz, key=lambda x: abs(x[1]), reverse=True)\n",
    "            keep = {tic for tic, _ in nz_sorted[: self.max_positions]}\n",
    "            for tic, w in nz:\n",
    "                if tic not in keep:\n",
    "                    new_weights[tic] = 0.0\n",
    "\n",
    "        # 2) limit the total leverage (by the sum of absolute values)\n",
    "        gross = sum(abs(w) for w in new_weights.values())\n",
    "        if gross > 0 and gross > self.gross_leverage:\n",
    "            scale = self.gross_leverage / gross\n",
    "            for tic in new_weights:\n",
    "                new_weights[tic] *= scale\n",
    "\n",
    "        self.current_weights = new_weights\n",
    "\n",
    "    # single stock weight adjustment logic\n",
    "    def _update_weight_one_name(\n",
    "        self,\n",
    "        old_weight: float,\n",
    "        target_sign: int,\n",
    "        close_only: bool,\n",
    "        target_weight: float,\n",
    "    ) -> float:\n",
    "        w = float(old_weight)\n",
    "\n",
    "        # in close-only mode, only reduce the position\n",
    "        if close_only and target_sign != 0:\n",
    "            return w  # do not open new positions\n",
    "\n",
    "        if target_sign == 0:\n",
    "            # immediately close\n",
    "            return 0.0\n",
    "\n",
    "        # open new positions or add positions or flip positions: directly set the target position\n",
    "        return target_sign * target_weight\n",
    "\n",
    "    def _apply_min_weight_threshold(self, w: float) -> float:\n",
    "        \"\"\"\n",
    "            when the absolute value is less than min_weight, directly treat it as 0 (close),\n",
    "            to prevent \"dirty positions\" like 0.01.\n",
    "        \"\"\"\n",
    "        if abs(w) < self.min_weight:\n",
    "            return 0.0\n",
    "        return w\n",
    "    def _compute_target_weights(self, signal_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        根据 signal_df 计算目标权重矩阵，遵守以下约束：\n",
    "        1. 单股最大仓位 ≤ 20%\n",
    "        2. 单股最小仓位 ≥ 2%\n",
    "        3. 卖空仓位也计算在总仓位中（取绝对值）\n",
    "        4. ratio 控制总可用仓位比例（默认 1.0）\n",
    "        5. 最多 20 只股票（超出则随机抽取）\n",
    "        6. 新股票只用剩余仓位买入，不调整已有仓位\n",
    "        7. 每月最后一个交易日做等权 Rebalance\n",
    "        \"\"\"\n",
    "        random.seed(42)\n",
    "        max_weight = self.max_weight\n",
    "        min_weight = self.min_weight\n",
    "        ratio = getattr(self, \"ratio\", 1.0)\n",
    "        max_positions = self.max_positions\n",
    "\n",
    "        dates = sorted(pd.to_datetime(signal_df.index.unique()))\n",
    "        all_tics = signal_df.columns\n",
    "        weights_target = pd.DataFrame(index=dates, columns=all_tics, dtype=float).fillna(0.0)\n",
    "\n",
    "        current_holdings = set()\n",
    "        last_weights = pd.Series(0.0, index=all_tics)   #\n",
    "\n",
    "\n",
    "        for date in dates:\n",
    "            cal = self.universe_mgr.trading_calendar\n",
    "            month_dates = [d for d in cal if d.year == date.year and d.month == date.month]\n",
    "            if not month_dates:\n",
    "                continue\n",
    "            month_dates = sorted(month_dates)\n",
    "\n",
    "            # 第二个交易日与月底\n",
    "            signal_day = month_dates[1] if len(month_dates) >= 2 else month_dates[0]\n",
    "            last_day = month_dates[-1]\n",
    "            is_signal_day = date.normalize() == pd.Timestamp(signal_day).normalize()\n",
    "            is_month_end = date.normalize() == pd.Timestamp(last_day).normalize()\n",
    "\n",
    "            # --- 每月第二个交易日：根据信号建仓 ---\n",
    "            if is_signal_day:\n",
    "                row = signal_df.loc[date] if date in signal_df.index else None\n",
    "                if row is None:\n",
    "                    weights_target.loc[date] = last_weights\n",
    "                    continue\n",
    "\n",
    "                active_tics = [tic for tic, sig in row.items() if sig != 0]\n",
    "                if not active_tics:\n",
    "                    weights_target.loc[date] = last_weights\n",
    "                    continue\n",
    "\n",
    "                if len(active_tics) > max_positions:\n",
    "                    active_tics = random.sample(active_tics, max_positions)\n",
    "\n",
    "                equal_w = min(max_weight, max(min_weight, ratio / len(active_tics)))\n",
    "                new_weights = pd.Series(0.0, index=all_tics)\n",
    "                for tic in active_tics:\n",
    "                    new_weights[tic] = row[tic] * equal_w\n",
    "\n",
    "                last_weights = new_weights.copy()\n",
    "                weights_target.loc[date] = last_weights\n",
    "                current_holdings = set(active_tics)\n",
    "\n",
    "            # --- 月底 Rebalance ---\n",
    "            elif is_month_end and len(current_holdings) > 0:\n",
    "                equal_w = min(max_weight, max(min_weight, ratio / len(current_holdings)))\n",
    "                new_weights = pd.Series(0.0, index=all_tics)\n",
    "                for tic in current_holdings:\n",
    "                    sig = 1 if last_weights.get(tic, 0) >= 0 else -1\n",
    "                    new_weights[tic] = sig * equal_w\n",
    "\n",
    "                last_weights = new_weights.copy()\n",
    "                weights_target.loc[date] = last_weights\n",
    "\n",
    "            # --- 其他日期：延续上次仓位 ---\n",
    "            else:\n",
    "                weights_target.loc[date] = last_weights\n",
    "\n",
    "        # 最后再清理\n",
    "        weights_target = weights_target.fillna(0.0)\n",
    "        return weights_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a2d411",
   "metadata": {},
   "source": [
    "# base signaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "99e7d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Iterable\n",
    "\n",
    "class BaseSignalEngine:\n",
    "    \"\"\"\n",
    "    BaseSignalEngine (Rebuilt Clean Version)\n",
    "    ---------------------------------------\n",
    "    负责：\n",
    "        ✓ 多文件/单文件读取\n",
    "        ✓ chunk 加载\n",
    "        ✓ 字段映射 col_map\n",
    "        ✓ 为每个 tic 调用 generate_signal_one_ticker()\n",
    "        ✓ 与 Universe / Position 做基本过滤\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        strategy_name=\"default\",\n",
    "        col_map=None,\n",
    "        universe_mgr=None,\n",
    "        logger=None,\n",
    "        chunk_size=200000,\n",
    "        multi_file=True,\n",
    "        #signal are generated in this period\n",
    "        signal_start_date=None,\n",
    "        signal_end_date=None,\n",
    "\n",
    "        # data are read in this period\n",
    "        data_start_date=None,\n",
    "        data_end_date=None\n",
    "    ):\n",
    "        self.strategy_name = strategy_name\n",
    "        self.universe_mgr = universe_mgr\n",
    "        self.chunk_size = chunk_size\n",
    "        self.multi_file = multi_file\n",
    "        #  time parameters are parsed in advance\n",
    "        self.signal_start_date = pd.to_datetime(signal_start_date) if signal_start_date else None\n",
    "        self.signal_end_date   = pd.to_datetime(signal_end_date) if signal_end_date else None\n",
    "        self.data_start_date   = pd.to_datetime(data_start_date) if data_start_date else None\n",
    "        self.data_end_date     = pd.to_datetime(data_end_date) if data_end_date else None\n",
    "\n",
    "        # 统一内部列名\n",
    "        self.col_map = col_map or {\n",
    "            \"datetime\": \"date\",\n",
    "            \"open\": \"open\",\n",
    "            \"high\": \"high\",\n",
    "            \"low\": \"low\",\n",
    "            \"close\": \"close\",\n",
    "            \"volume\": \"volume\",\n",
    "            \"tic\": \"tic\"\n",
    "        }\n",
    "\n",
    "        self.logger = logger or StrategyLogger(strategy_name)\n",
    "\n",
    "    # ===============================================================\n",
    "    # 多文件模式：每个股票一个 CSV\n",
    "    # ===============================================================\n",
    "    def load_price_data_multi_file(self, folder, tics):\n",
    "        price_dict = {}\n",
    "\n",
    "        for tic in tics:\n",
    "            path = os.path.join(folder, f\"{tic}_daily.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                self.logger.log_error(f\"[WARN] Missing file: {path}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[READ] {path} ...\")\n",
    "\n",
    "            chunks = []\n",
    "            for chunk in pd.read_csv(path, chunksize=self.chunk_size):\n",
    "\n",
    "                # rename_map：内部名 ← 文件名\n",
    "                rename_map = {\n",
    "                    file_col: internal_col\n",
    "                    for internal_col, file_col in self.col_map.items()\n",
    "                    if file_col in chunk.columns\n",
    "                }\n",
    "                chunk = chunk.rename(columns=rename_map)\n",
    "\n",
    "                # 强制加入 tic\n",
    "                chunk[\"tic\"] = tic\n",
    "\n",
    "                # 统一 datetime\n",
    "                if \"datetime\" in chunk.columns:\n",
    "                    chunk[\"date\"] = pd.to_datetime(chunk[\"datetime\"])\n",
    "                    chunk.drop(columns=[\"datetime\"], inplace=True)   # === NEW === 删除冗余列\n",
    "                elif \"date\" in chunk.columns:\n",
    "                    chunk[\"date\"] = pd.to_datetime(chunk[\"date\"])\n",
    "                else:\n",
    "                    raise ValueError(f\"{path} 缺少 date/datetime 列\")\n",
    "                # === data time filter ===\n",
    "                if self.data_start_date is not None:\n",
    "                    chunk = chunk[chunk[\"date\"] >= self.data_start_date]\n",
    "                if self.data_end_date is not None:\n",
    "                    chunk = chunk[chunk[\"date\"] <= self.data_end_date]\n",
    "\n",
    "                # === skip empty chunk ===\n",
    "                if chunk.empty:\n",
    "                    continue\n",
    "\n",
    "                chunks.append(chunk)\n",
    "\n",
    "            df = pd.concat(chunks, ignore_index=True)\n",
    "            df = df.sort_values(\"date\")\n",
    "\n",
    "            price_dict[tic] = df\n",
    "            print(f\"      ✓ loaded {len(df)} rows for {tic}\")\n",
    "\n",
    "        return price_dict\n",
    "\n",
    "    # ===============================================================\n",
    "    # 单文件模式（很少使用）\n",
    "    # ===============================================================\n",
    "    def load_price_data_single_file(self, filepath):\n",
    "        print(f\"[READ] Big file in chunks: {filepath}\")\n",
    "\n",
    "        chunks = []\n",
    "        for chunk in pd.read_csv(filepath, chunksize=self.chunk_size):\n",
    "            rename_map = {\n",
    "                file_col: internal_col\n",
    "                for internal_col, file_col in self.col_map.items()\n",
    "                if file_col in chunk.columns\n",
    "            }\n",
    "            chunk = chunk.rename(columns=rename_map)\n",
    "\n",
    "            if \"datetime\" in chunk.columns:\n",
    "                chunk[\"date\"] = pd.to_datetime(chunk[\"datetime\"])\n",
    "                chunk.drop(columns=[\"datetime\"], inplace=True)   # === NEW === 删除冗余列\n",
    "\n",
    "            elif \"date\" in chunk.columns:\n",
    "                chunk[\"date\"] = pd.to_datetime(chunk[\"date\"])\n",
    "            else:\n",
    "                raise ValueError(\"文件缺少 date/datetime 列\")\n",
    "\n",
    "            # === data time filter ===\n",
    "            if self.data_start_date is not None:\n",
    "                chunk = chunk[chunk[\"date\"] >= self.data_start_date]\n",
    "            if self.data_end_date is not None:\n",
    "                chunk = chunk[chunk[\"date\"] <= self.data_end_date]\n",
    "\n",
    "            # === skip empty chunk ===\n",
    "            if chunk.empty:\n",
    "                continue\n",
    "\n",
    "\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "        df = df.sort_values([\"tic\", \"date\"])\n",
    "        return df\n",
    "        \n",
    "    # expand signal to daily, weekly, monthly\n",
    "\n",
    "    def _expand_signal_to_daily(self, signal_df):\n",
    "        freq = self.get_signal_frequency()\n",
    "\n",
    "        # 需要 trading calendar，由 UniverseManager 提供\n",
    "        cal = pd.DatetimeIndex(self.universe_mgr.trading_calendar)\n",
    "\n",
    "        # -------- 日频：不需要扩展 --------\n",
    "        if freq == \"D\":\n",
    "            return signal_df.reindex(cal).fillna(0)\n",
    "\n",
    "        # -------- 周频：覆盖至下次周信号 --------\n",
    "        if freq == \"W\":\n",
    "            idx = signal_df.index\n",
    "            next_idx = list(idx[1:]) + [idx[-1] + pd.Timedelta(days=7)]\n",
    "            \n",
    "            records = []\n",
    "            for start, end in zip(idx, next_idx):\n",
    "                mask = (cal >= start) & (cal < end)\n",
    "                for d in cal[mask]:\n",
    "                    s = signal_df.loc[start]\n",
    "                    records.append( (d, s) )\n",
    "\n",
    "            out = pd.DataFrame({\"date\": [r[0] for r in records]}).set_index(\"date\")\n",
    "            for col in signal_df.columns:\n",
    "                out[col] = [r[1][col] for r in records]\n",
    "            return out\n",
    "\n",
    "        # -------- 月频：覆盖至下次月信号 --------\n",
    "        if freq == \"M\":\n",
    "            idx = signal_df.index\n",
    "            next_idx = list(idx[1:]) + [idx[-1] + pd.offsets.MonthEnd(1)]\n",
    "\n",
    "            records = []\n",
    "            for start, end in zip(idx, next_idx):\n",
    "                mask = (cal >= start) & (cal < end)\n",
    "                for d in cal[mask]:\n",
    "                    s = signal_df.loc[start]\n",
    "                    records.append((d, s))\n",
    "\n",
    "            out = pd.DataFrame({\"date\": [r[0] for r in records]}).set_index(\"date\")\n",
    "            for col in signal_df.columns:\n",
    "                out[col] = [r[1][col] for r in records]\n",
    "            return out\n",
    "\n",
    "        raise ValueError(f\"Unsupported signal freq: {freq}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 主方法：生成 signal_df（date × tic）\n",
    "    # ===============================================================\n",
    "    def compute_signals(self, price_source, tics, position_df=None):\n",
    "\n",
    "        # ---- Step 1: 读入 ----\n",
    "        if self.multi_file:\n",
    "            price_dict = self.load_price_data_multi_file(price_source, tics)\n",
    "            full_df = pd.concat(price_dict.values(), ignore_index=True)\n",
    "        else:\n",
    "            full_df = self.load_price_data_single_file(price_source)\n",
    "        # === data time filter ===\n",
    "        if self.data_start_date is not None:\n",
    "            full_df = full_df[full_df[\"date\"] >= self.data_start_date]\n",
    "        if self.data_end_date is not None:\n",
    "            full_df = full_df[full_df[\"date\"] <= self.data_end_date]\n",
    "\n",
    "        # ---- Step 2: 当前持仓 ----\n",
    "        positions = {}\n",
    "        if position_df is not None and len(position_df) > 0:\n",
    "            positions = dict(zip(position_df[\"tic\"], position_df[\"weight\"]))\n",
    "\n",
    "        # ---- Step 3: 为每只股票生成信号 ----\n",
    "        signal_list = []\n",
    "        for tic in tics:\n",
    "            sub = full_df[full_df[\"tic\"] == tic]\n",
    "            if sub.empty:\n",
    "                continue\n",
    "\n",
    "            sig = self.generate_signal_one_ticker(sub)\n",
    "\n",
    "            # === NEW: 信号时间过滤 ===\n",
    "            if self.signal_start_date is not None:\n",
    "                sig = sig[sig.index >= self.signal_start_date]\n",
    "            if self.signal_end_date is not None:\n",
    "                sig = sig[sig.index <= self.signal_end_date]\n",
    "            sig.name = tic\n",
    "            signal_list.append(sig)\n",
    "            self.logger.log_raw_signal(tic, sig)\n",
    "\n",
    "        signal_df = pd.concat(signal_list, axis=1).fillna(0)\n",
    "        signal_df.to_csv(\"./log/signal_df.csv\")\n",
    "        final_df = self._expand_signal_to_daily(signal_df)\n",
    "        # =========================================================\n",
    "        # filter daily signals by universe \n",
    "        # =========================================================\n",
    "        if self.universe_mgr is not None:\n",
    "            univ_mgr = self.universe_mgr\n",
    "\n",
    "            # get all trading dates\n",
    "            dates = final_df.index\n",
    "\n",
    "            # get all columns (tic)\n",
    "            all_tics = final_df.columns\n",
    "\n",
    "            # build a mask for each date, set the signal of stocks not in the universe to 0\n",
    "            mask_matrix = []\n",
    "            for d in dates:\n",
    "                todays_universe = univ_mgr.get_universe(d)\n",
    "                mask = all_tics.isin(todays_universe)  # True=keep，False=0\n",
    "                \n",
    "                if hasattr(mask, 'values'):\n",
    "                    mask_matrix.append(mask.values)\n",
    "                else:\n",
    "                    # 如果 mask 已经是 numpy array，直接 append\n",
    "                    mask_matrix.append(mask)\n",
    "            mask_matrix = np.vstack(mask_matrix)  # shape=(n_dates, n_tics)\n",
    "\n",
    "            # use mask to filter the signal of stocks not in the universe\n",
    "            final_df = final_df.where(mask_matrix, 0)\n",
    "        return final_df\n",
    "    def get_signal_frequency(self) -> str:\n",
    "        \"\"\"\n",
    "        返回策略生成信号的频率：\n",
    "            \"D\": 日度\n",
    "            \"W\": 周度\n",
    "            \"M\": 月度\n",
    "        子类应该覆盖。\n",
    "        \"\"\"\n",
    "        return \"D\"  # 默认日度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889db55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08b5bbe5",
   "metadata": {},
   "source": [
    "### TSMOM 策略子类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6c76a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Iterable\n",
    "#from StrategyLogger import StrategyLogger\n",
    "#from BaseSignalEngine import BaseSignalEngine\n",
    "class TSMOMSignalEngine(BaseSignalEngine):\n",
    "    \"\"\"\n",
    "    TS-MOM (Moskowitz et al., 2012)\n",
    "    --------------------------------\n",
    "    严格使用“月度价格”计算信号：\n",
    "        ret_12m = P(t-1m) / P(t-12m) - 1\n",
    "    信号是月度频率（M），最终会在 BaseSignalEngine 中扩展成 daily。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        strategy_name=\"tsmom\",\n",
    "        col_map=None,\n",
    "        universe_mgr=None,\n",
    "        logger=None,\n",
    "        chunk_size=200000,\n",
    "        multi_file=True,\n",
    "        lookback_months=12,      # lookback 按月\n",
    "        neutral_band=0.10,       # 信号区间\n",
    "        # === NEW: 信号时间区间 ===\n",
    "        signal_start_date=None,\n",
    "        signal_end_date=None,\n",
    "        data_start_date=None,\n",
    "        data_end_date=None\n",
    "    ):\n",
    "        # === FIX: 你原来 super 传参错位置，这里纠正 ===\n",
    "        super().__init__(\n",
    "            strategy_name=strategy_name,\n",
    "            col_map=col_map,\n",
    "            universe_mgr=universe_mgr,\n",
    "            logger=logger,\n",
    "            chunk_size=chunk_size,\n",
    "            multi_file=multi_file,\n",
    "            # === NEW: 信号时间区间传入基类 ===\n",
    "            signal_start_date=signal_start_date,\n",
    "            signal_end_date=signal_end_date,\n",
    "            data_start_date=data_start_date,\n",
    "            data_end_date=data_end_date\n",
    "        )\n",
    "\n",
    "        self.lookback_months = lookback_months\n",
    "        self.neutral_band = neutral_band\n",
    "\n",
    "        # === NEW: data_end_date 默认等于 signal_end_date ===\n",
    "        if self.data_end_date is None:\n",
    "            self.data_end_date = self.signal_end_date\n",
    "\n",
    "        # === NEW: logger record ===\n",
    "        if self.logger:\n",
    "            self.logger.log_error(\n",
    "                f\"[TSMOM INIT] signal=[{self.signal_start_date} ~ {self.signal_end_date}], \"\n",
    "                f\"data=[{self.data_start_date} ~ {self.data_end_date}], \"\n",
    "                f\"lookback_months={self.lookback_months}\"\n",
    "            )\n",
    "\n",
    "    # =====================================================\n",
    "    # === NEW: 告诉 BaseSignalEngine 我是月度频率 (M) ===\n",
    "    # =====================================================\n",
    "    def get_signal_frequency(self):\n",
    "        return \"M\"\n",
    "\n",
    "    # =====================================================\n",
    "    # 单股票的月度信号生成\n",
    "    # =====================================================\n",
    "    def generate_signal_one_ticker(self, df):\n",
    "\n",
    "        # === NEW: 数据时间过滤 (data_start / data_end) ===\n",
    "        if self.data_start_date is not None:\n",
    "            df = df[df[\"date\"] >= self.data_start_date]\n",
    "        if self.data_end_date is not None:\n",
    "            df = df[df[\"date\"] <= self.data_end_date]\n",
    "\n",
    "        df = df.sort_values(\"date\").copy()\n",
    "\n",
    "        # ========================\n",
    "        # ① 按月取最后一天价格\n",
    "        # ========================\n",
    "        df_m = (\n",
    "            df.resample(\"M\", on=\"date\")\n",
    "              .last()[[\"close\"]]\n",
    "              .dropna()\n",
    "        )\n",
    "\n",
    "        # ========================\n",
    "        # ② 计算 12 个月动量\n",
    "        # ========================\n",
    "        df_m[\"ret_12m\"] = (\n",
    "            df_m[\"close\"].shift(1) / df_m[\"close\"].shift(self.lookback_months) - 1\n",
    "        )\n",
    "\n",
    "        # ========================\n",
    "        # ③ 生成月度信号\n",
    "        # ========================\n",
    "        sig = pd.Series(0, index=df_m.index)\n",
    "\n",
    "        sig[df_m[\"ret_12m\"] > +self.neutral_band] = 1\n",
    "        sig[df_m[\"ret_12m\"] < -self.neutral_band] = -1\n",
    "\n",
    "        sig.index.name = \"date\"\n",
    "\n",
    "        # === NEW: 信号窗口过滤 ===\n",
    "        if self.signal_start_date is not None:\n",
    "            sig = sig[sig.index >= self.signal_start_date]\n",
    "        if self.signal_end_date is not None:\n",
    "            sig = sig[sig.index <= self.signal_end_date]\n",
    "\n",
    "        return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7190b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_selected = pd.read_csv(\n",
    "    \"./data/test_stock_selected.csv\",\n",
    "    parse_dates=[\"trade_date\"]\n",
    ")\n",
    "stock_selected.head()\n",
    "stock_selected[\"trade_date\"] = stock_selected[\"trade_date\"].dt.tz_localize(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8e2208d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    \"tic_name\": \"tic\",           # 内部 tic_name 对应文件中的 tic 字段\n",
    "    \"trade_date\": \"trade_date\",  # 内部 trade_date 对应文件中的 trade_date 字段\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e969de19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic_name</th>\n",
       "      <th>in_universe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-02 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-02 21:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-03 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-03 21:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-04 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-03-04 21:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-03-05 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-05 21:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-06 21:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-03-06 21:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-03-09 20:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-09 20:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-03-10 20:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-03-10 20:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-03-11 20:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-03-11 20:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-03-12 20:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-03-12 20:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-03-13 20:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-03-13 20:00:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date tic_name  in_universe\n",
       "0  2020-03-02 21:00:00     AAPL            1\n",
       "1  2020-03-02 21:00:00     NVDA            1\n",
       "2  2020-03-03 21:00:00     AAPL            1\n",
       "3  2020-03-03 21:00:00     NVDA            1\n",
       "4  2020-03-04 21:00:00     AAPL            1\n",
       "5  2020-03-04 21:00:00     NVDA            1\n",
       "6  2020-03-05 21:00:00     AAPL            1\n",
       "7  2020-03-05 21:00:00     NVDA            1\n",
       "8  2020-03-06 21:00:00     AAPL            1\n",
       "9  2020-03-06 21:00:00     NVDA            1\n",
       "10 2020-03-09 20:00:00     AAPL            1\n",
       "11 2020-03-09 20:00:00     NVDA            1\n",
       "12 2020-03-10 20:00:00     AAPL            1\n",
       "13 2020-03-10 20:00:00     NVDA            1\n",
       "14 2020-03-11 20:00:00     AAPL            1\n",
       "15 2020-03-11 20:00:00     NVDA            1\n",
       "16 2020-03-12 20:00:00     AAPL            1\n",
       "17 2020-03-12 20:00:00     NVDA            1\n",
       "18 2020-03-13 20:00:00     AAPL            1\n",
       "19 2020-03-13 20:00:00     NVDA            1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n"
     ]
    }
   ],
   "source": [
    "logger = StrategyLogger(\"TSMOM\")\n",
    "\n",
    "uni_mgr = UniverseManager(\n",
    "    stock_selection_df=stock_selected,\n",
    "    col_map=col_map,\n",
    "    trading_calendar=nyse_dates,\n",
    "    logger=logger ,    # 或者放入你自己的 logger\n",
    "    backtest_start=\"2020-03-01\",\n",
    "    backtest_end=\"2021-12-31\"\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "uni_mgr.universe_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c200af9",
   "metadata": {},
   "source": [
    "signal_df ： \n",
    "\n",
    "date\tAAPL\tMSFT\tAMZN\t…\n",
    "2020-01-02\t1\t0\t-1\t…\n",
    "2020-01-03\t0\t1\t0\t…\n",
    "2020-01-06\t-1\t0\t1\t…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "573dbf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tickers: 5\n",
      "['AAPL', 'AMD', 'AMZN', 'NVDA', 'TSLA']\n"
     ]
    }
   ],
   "source": [
    "# 从 universe 提取全部股票列表\n",
    "all_tics = sorted(stock_selected[\"tic\"].unique())\n",
    "print(\"Number of tickers:\", len(all_tics))\n",
    "print(all_tics[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "263d8e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[READ] ./data/fmp_daily\\AAPL_daily.csv ...\n",
      "      ✓ loaded 757 rows for AAPL\n",
      "[READ] ./data/fmp_daily\\AMD_daily.csv ...\n",
      "      ✓ loaded 757 rows for AMD\n",
      "[READ] ./data/fmp_daily\\AMZN_daily.csv ...\n",
      "      ✓ loaded 757 rows for AMZN\n",
      "[READ] ./data/fmp_daily\\NVDA_daily.csv ...\n",
      "      ✓ loaded 757 rows for NVDA\n",
      "[READ] ./data/fmp_daily\\TSLA_daily.csv ...\n",
      "      ✓ loaded 757 rows for TSLA\n",
      "Signal DF:\n",
      "                     AAPL  AMD  AMZN  NVDA  TSLA\n",
      "date                                            \n",
      "2022-01-24 21:00:00     0    1     0     0     1\n",
      "2022-01-25 21:00:00     0    1     0     0     1\n",
      "2022-01-26 21:00:00     0    1     0     0     1\n",
      "2022-01-27 21:00:00     0    1     0     0     1\n",
      "2022-01-28 21:00:00     0    1     0     0     1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Step 2 — Signal Engine（月度 TS-MOM）\n",
    "# ============================================================\n",
    "sig_engine = TSMOMSignalEngine(\n",
    "    strategy_name=\"tsmom\",\n",
    "    universe_mgr=uni_mgr,\n",
    "    logger=logger,\n",
    "    multi_file=True,          # 多文件模式\n",
    "    lookback_months=12,\n",
    "    neutral_band=0.10,\n",
    "    signal_start_date=\"2020-03-01\",\n",
    "    signal_end_date=\"2021-12-31\",\n",
    "    data_start_date=\"2019-01-01\",\n",
    "    data_end_date=\"2021-12-31\"\n",
    ")\n",
    "\n",
    "signal_df = sig_engine.compute_signals(\n",
    "    \"./data/fmp_daily\",\n",
    "    all_tics\n",
    ")\n",
    "\n",
    "print(\"Signal DF:\")\n",
    "print(signal_df.tail())\n",
    "signal_df.to_csv(\"./log/signal_dffull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1860f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df.to_csv(\"./log/signal_dffull.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "01450215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights DF:\n",
      "                     AAPL  AMD  AMZN  NVDA  TSLA\n",
      "date                                            \n",
      "2022-01-24 21:00:00   0.0  0.2   0.0   0.0   0.2\n",
      "2022-01-25 21:00:00   0.0  0.2   0.0   0.0   0.2\n",
      "2022-01-26 21:00:00   0.0  0.2   0.0   0.0   0.2\n",
      "2022-01-27 21:00:00   0.0  0.2   0.0   0.0   0.2\n",
      "2022-01-28 21:00:00   0.0  0.2   0.0   0.0   0.2\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Step 3 — ExecutionManager（月度调仓）\n",
    "# ============================================================\n",
    "exe_mgr = ExecutionManager(\n",
    "    universe_mgr=uni_mgr,\n",
    "    rebalance_freq=\"M\",\n",
    "    cooling_days=0,\n",
    "    logger=logger,\n",
    "    max_positions=20,\n",
    "    max_weight=0.20,\n",
    "    min_weight=0.05\n",
    ")\n",
    "\n",
    "weights_df = exe_mgr.generate_weight_matrix(signal_df)\n",
    "weights_df.to_csv(\"./log/weights_df.csv\")\n",
    "print(\"Weights DF:\")\n",
    "print(weights_df.tail())\n",
    "print(len(logger.signal_logs))\n",
    "print(len(logger.portfolio_logs))\n",
    "print(len(logger.universe_logs))\n",
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72464130",
   "metadata": {},
   "source": [
    "## Asyncronize mode log split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "40e1a3b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 8, saw 9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[169]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m log_path = \u001b[33m\"\u001b[39m\u001b[33m./log/strategy_tsmom/2025-11-22/async_logs.csv\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(log_path):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# 按 category 拆分\u001b[39;00m\n\u001b[32m     10\u001b[39m     signals = df[df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33msignal\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\LLM-study\\FinRL-Trading-refactor\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\LLM-study\\FinRL-Trading-refactor\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\LLM-study\\FinRL-Trading-refactor\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\LLM-study\\FinRL-Trading-refactor\\myenv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 2 fields in line 8, saw 9\n"
     ]
    }
   ],
   "source": [
    "# After pipeline finished, split the log into three parts\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "log_path = \"./log/strategy_tsmom/2025-11-22/async_logs.csv\" \n",
    "if os.path.exists(log_path):\n",
    "    df = pd.read_csv(log_path)\n",
    "    \n",
    "    # 按 category 拆分\n",
    "    signals = df[df['category'] == 'signal']\n",
    "    portfolios = df[df['category'] == 'portfolio']\n",
    "    universe = df[df['category'] == 'universe']\n",
    "    \n",
    "    # 保存\n",
    "    signals.to_csv(\"./log/strategy_tsmom/clean_signal_logs.csv\", index=False)\n",
    "    portfolios.to_csv(\"./log/strategy_tsmom/clean_portfolio_logs.csv\", index=False)\n",
    "    print(f\"Split logs: {len(signals)} signals, {len(portfolios)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d22361",
   "metadata": {},
   "source": [
    "## one big file daily_SPX_500_feature_engineering.csv for data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "51741231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "# === parameter configuration ===\n",
    "CONFIG = {\n",
    "    \"price_file\": \"./feature/daily_SPX_500_feature_engineering.csv\",\n",
    "    \"universe_file\": \"./data/stock_selected_updated.csv\",\n",
    "    \n",
    "    \"data_start_date\": \"2016-06-01\",\n",
    "    \"data_end_date\": \"2024-12-31\",\n",
    "    \"backtest_start_date\": \"2018-01-01\",\n",
    "    \"backtest_end_date\": \"2024-12-31\",\n",
    "    \n",
    "    # === 基于文件头的列名映射 ===\n",
    "    \"col_map\": {\n",
    "        # Stock Selected File Mappings\n",
    "        \"tic_name\": \"tic\",\n",
    "        \"trade_date\": \"trade_date\",\n",
    "        \n",
    "        # Price File Mappings (左: 内部标准名, 右: CSV列名)\n",
    "        \"datetime\": \"datadate\",  # 日期列\n",
    "        \"tic\": \"tic\",            # 股票代码\n",
    "        \n",
    "        # 价格字段\n",
    "        \"open\": \"prcod\",         # 开盘价 (如果为空，部分逻辑可能需要 fillna)\n",
    "        \"high\": \"prchd\",         # 最高价\n",
    "        \"low\": \"prcld\",          # 最低价\n",
    "        \"close\": \"adj_close\",    # 收盘价 (建议优先用复权后的 adj_close 计算收益)\n",
    "                                 # 如果没有 adj_close，改用 \"prccd\"\n",
    "        \"volume\": \"cshtrd\"       # 成交量\n",
    "    }\n",
    "}\n",
    "# 获取交易日历 (NYSE)\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "schedule = nyse.schedule(start_date=\"2016-01-01\", end_date=\"2025-12-31\")\n",
    "trading_days = mcal.date_range(schedule, frequency='1D').tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "641a06a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers in universe: 705\n"
     ]
    }
   ],
   "source": [
    "# load stock selected data ===\n",
    "stock_selected = pd.read_csv(\n",
    "    CONFIG[\"universe_file\"],\n",
    "    parse_dates=[\"trade_date\"]\n",
    ")\n",
    "\n",
    "logger = StrategyLogger(\"TSMOM\", async_mode=False) \n",
    "\n",
    "\n",
    "# initialize UniverseManager\n",
    "uni_mgr = UniverseManager(\n",
    "    stock_selection_df=stock_selected,\n",
    "    col_map=CONFIG[\"col_map\"],\n",
    "    trading_calendar=trading_days,\n",
    "    backtest_start=CONFIG[\"backtest_start_date\"],\n",
    "    backtest_end=CONFIG[\"backtest_end_date\"],\n",
    "    logger=logger  # 假设您已初始化 logger\n",
    ")\n",
    "\n",
    "all_tics = sorted(stock_selected[\"tic\"].unique())\n",
    "print(f\"Total tickers in universe: {len(all_tics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5982dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize signal engine ===\n",
    "sig_engine = TSMOMSignalEngine(\n",
    "    strategy_name=\"tsmom_spx\",\n",
    "    universe_mgr=uni_mgr,\n",
    "    logger=logger,\n",
    "    \n",
    "    # single file mode configuration\n",
    "    multi_file=False,  \n",
    "    chunk_size=500000,  \n",
    "    \n",
    "    # strategy parameters\n",
    "    lookback_months=12,\n",
    "    neutral_band=0.10,\n",
    "    \n",
    "    # 时间区间\n",
    "    signal_start_date=CONFIG[\"backtest_start_date\"], # 2018-01-01\n",
    "    signal_end_date=CONFIG[\"backtest_end_date\"],     # 2024-12-31\n",
    "    data_start_date=CONFIG[\"data_start_date\"],       # 2016-06-01 \n",
    "    data_end_date=CONFIG[\"data_end_date\"],\n",
    "    \n",
    "    col_map=CONFIG[\"col_map\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "84ea5f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[READ] Big file in chunks: ./feature/daily_SPX_500_feature_engineering.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal DF Head:\n",
      "                       A  AAL  AAP  AAPL  ABBV  ABNB  ABT  ACGL  ACN  ADBE  \\\n",
      "date                                                                         \n",
      "2018-01-31 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2018-02-01 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2018-02-02 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2018-02-05 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2018-02-06 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "\n",
      "                     ...  XEL  XOM  XRAY  XRX  XYL  YUM  ZBH  ZBRA  ZION  ZTS  \n",
      "date                 ...                                                       \n",
      "2018-01-31 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  \n",
      "2018-02-01 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  \n",
      "2018-02-02 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  \n",
      "2018-02-05 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  \n",
      "2018-02-06 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  \n",
      "\n",
      "[5 rows x 705 columns]\n",
      "Signal DF Tail:\n",
      "                       A  AAL  AAP  AAPL  ABBV  ABNB  ABT  ACGL  ACN  ADBE  \\\n",
      "date                                                                         \n",
      "2025-01-24 21:00:00  0.0  0.0 -1.0   0.0   1.0   0.0  0.0   1.0  0.0  -1.0   \n",
      "2025-01-27 21:00:00  0.0  0.0 -1.0   0.0   1.0   0.0  0.0   1.0  0.0  -1.0   \n",
      "2025-01-28 21:00:00  0.0  0.0 -1.0   0.0   1.0   0.0  0.0   1.0  0.0  -1.0   \n",
      "2025-01-29 21:00:00  0.0  0.0 -1.0   0.0   1.0   0.0  0.0   1.0  0.0  -1.0   \n",
      "2025-01-30 21:00:00  0.0  0.0 -1.0   0.0   1.0   0.0  0.0   1.0  0.0  -1.0   \n",
      "\n",
      "                     ...  XEL  XOM  XRAY  XRX  XYL  YUM  ZBH  ZBRA  ZION  ZTS  \n",
      "date                 ...                                                       \n",
      "2025-01-24 21:00:00  ...  1.0  0.0   0.0 -1.0  0.0  0.0  0.0   0.0   0.0 -1.0  \n",
      "2025-01-27 21:00:00  ...  1.0  0.0   0.0 -1.0  0.0  0.0  0.0   0.0   0.0 -1.0  \n",
      "2025-01-28 21:00:00  ...  1.0  0.0   0.0 -1.0  0.0  0.0  0.0   0.0   0.0 -1.0  \n",
      "2025-01-29 21:00:00  ...  1.0  0.0   0.0 -1.0  0.0  0.0  0.0   0.0   0.0 -1.0  \n",
      "2025-01-30 21:00:00  ...  1.0  0.0   0.0 -1.0  0.0  0.0  0.0   0.0   0.0 -1.0  \n",
      "\n",
      "[5 rows x 705 columns]\n"
     ]
    }
   ],
   "source": [
    "# === signal generation ===\n",
    "# for single file mode, the first parameter is the file path, the second parameter is the stock list (for filtering)\n",
    "\n",
    "signal_df = sig_engine.compute_signals(\n",
    "    CONFIG[\"price_file\"], \n",
    "    all_tics\n",
    ")\n",
    "signal_df.to_csv(\"./log/signal_dffull.csv\")\n",
    "print(\"Signal DF Head:\")\n",
    "print(signal_df.head())\n",
    "print(\"Signal DF Tail:\")\n",
    "print(signal_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ab666d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights DF:\n",
      "                       A  AAL  AAP  AAPL  ABBV  ABNB  ABT  ACGL  ACN  ADBE  \\\n",
      "date                                                                         \n",
      "2025-01-24 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2025-01-27 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2025-01-28 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2025-01-29 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "2025-01-30 21:00:00  0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  0.0   0.0   \n",
      "\n",
      "                     ...  XEL  XOM  XRAY  XRX  XYL  YUM  ZBH  ZBRA  ZION   ZTS  \n",
      "date                 ...                                                        \n",
      "2025-01-24 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0 -0.05  \n",
      "2025-01-27 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0 -0.05  \n",
      "2025-01-28 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0 -0.05  \n",
      "2025-01-29 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0 -0.05  \n",
      "2025-01-30 21:00:00  ...  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0   0.0 -0.05  \n",
      "\n",
      "[5 rows x 705 columns]\n",
      "25108\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "exe_mgr = ExecutionManager(\n",
    "    universe_mgr=uni_mgr,\n",
    "    rebalance_freq=\"M\",\n",
    "    cooling_days=0,\n",
    "    logger=logger,\n",
    "    max_positions=20,\n",
    "    max_weight=0.20,\n",
    "    min_weight=0.05\n",
    ")\n",
    "\n",
    "weights_df = exe_mgr.generate_weight_matrix(signal_df)\n",
    "weights_df.to_csv(\"./log/weights_df.csv\")\n",
    "print(\"Weights DF:\")\n",
    "print(weights_df.tail())\n",
    "print(len(logger.signal_logs))\n",
    "print(len(logger.portfolio_logs))\n",
    "print(len(logger.universe_logs))\n",
    "\n",
    "logger.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
